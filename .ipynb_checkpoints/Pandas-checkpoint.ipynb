{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e54ae5-ab6e-4845-8ea0-5d8f157ae038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as np # importiert pandas \n",
    "\n",
    "Dataframes # Mehrdimensionale Arrays\n",
    "Serie # 1 Dimensionales Array zB. Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c914cca-a134-45f4-bcb1-4cc2474f5f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Series\n",
    "s = pd.Series(data, index=index)\n",
    "l = [1980, 2020, 2001, 1999]\n",
    "series = pd.Series(l)\n",
    "\n",
    "pd.Series(d) # this creates a series from the dictionary 'd'\n",
    "new_series[1:3:2]\n",
    "new_series[\"d\"] #accessing elements by index label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928fad5f-eb7d-411e-96ce-aa528008f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.3. Methods in Series \n",
    "concat() is a pandas function used to concatenate and \n",
    "combine DataFrames along a specified axis, either vertically (rows) or horizontally (columns).\n",
    "\n",
    "s3 = pd.concat([new_series,new_series])\n",
    "s3\n",
    "\n",
    "sort_values() is a pandas DataFrame method that sorts the DataFrame based on specified column(s), \n",
    "while sort_index() sorts the DataFrame based on its index labels.\n",
    "\n",
    "titanic_series.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "value_counts() is a Pandas function that returns a Series containing the counts of unique values in a Series or DataFrame.\n",
    "titanic_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bbed90-7e89-491c-b320-aca434768357",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataframes in Pandas\n",
    "\n",
    "The head() method returns the first few rows of a DataFrame or Series, while the tail() method returns the last few rows.\n",
    "titanic_df.head(3)\n",
    "\n",
    "The index attribute in Pandas returns the index labels of a DataFrame or Series, \n",
    "and the columns attribute returns the column labels of a DataFrame.\n",
    "titanic_df.index\n",
    "list(titanic_df.index)\n",
    "titanic_df.columns\n",
    "list(titanic_df.columns)\n",
    "titanic_df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02e921-1e2f-41d2-b862-504e1bd55994",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data access in Dataframe\n",
    "Columns\n",
    "You can extract columns from a DataFrame using dictionary-like notation or as attributes, \n",
    "obtaining a Series object in both cases, provided the column label is a valid Python identifier.\n",
    "titanic_df[[\"Sex\", \"Fare\"]]\n",
    "\n",
    "Rows\n",
    "To access rows in a Pandas DataFrame, you can use the iloc attribute with integer-based indexing or the loc attribute with label-based indexing. \n",
    "For example, df.iloc[0] will access the first row, and df.loc['row_label'] will access the row with the specified label.\n",
    "\n",
    "df_index.loc[\"789B\"] #loc is used for label-based indexing to access rows.\n",
    "df_index.iloc[1] #df_index.iloc[1]\n",
    "\n",
    "\n",
    "Specific values\n",
    "Here's a summary of the different ways to access individual values in a Pandas DataFrame:\n",
    "\n",
    "df.loc[row_label][column_label]: Chooses the row with the label and then the value in that row with the column label.\n",
    "\n",
    "df.iloc[row_position][column_label]: Selects the row with the position and then the value in that row with the column label.\n",
    "\n",
    "df.loc[row_label, column_label]: Directly accesses the value using both row and column labels.\n",
    "\n",
    "df.iloc[row_position, column_position]: Directly accesses the value using both row and column positions.\n",
    "\n",
    "Note: you might see df[row_label][column_label], even though is less recommended that using loc()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f5164-d427-4894-b430-a898296f0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape\n",
    "shape is a Pandas attribute that returns a tuple representing the dimensions of a DataFrame or Series, \n",
    "indicating the number of rows and columns, while shape() is not a valid function in Pandas, \n",
    "and attempting to call it will result in an AttributeError.\n",
    "\n",
    "titanic_df.shape # gives a tuple (nr rows, nr columns)\n",
    "titanic_df.shape[1] #tuples are accesed like this. nr of columns\n",
    "titanic_df.shape[0] # nr of rows\n",
    "\n",
    "describe()\n",
    "describe() is a Pandas method that generates descriptive statistics of a DataFrame, \n",
    "providing information on count, mean, standard deviation, minimum, maximum, and quartiles for each numerical column.\n",
    "\n",
    "titanic_df.describe()\n",
    "titanic_df.describe(include=\"object\")\n",
    "titanic_df.describe(include=\"all\")\n",
    "\n",
    "info()\n",
    "info() is a Pandas method that provides a concise summary of a DataFrame, \n",
    "including information about the data types, non-null values, and memory usage.\n",
    "\n",
    "titanic_df.info()\n",
    "\n",
    "nunique() and unique()\n",
    "nunique() is a Pandas function that returns the number of unique elements in a Series or DataFrame, \n",
    "while unique() returns an array of unique elements in a Series or DataFrame.\n",
    "\n",
    "titanic_df.nunique() #number of unique values per column\n",
    "#see unique values of one column\n",
    "titanic_df.Pclass.unique()\n",
    "\n",
    "dtypes\n",
    "dtypes is a Pandas attribute that returns the data types of each column in a DataFrame, \n",
    "while dtype is a method that returns the data type of a single element in a Series or DataFrame.\n",
    "\n",
    "titanic_df.dtypes\n",
    "\n",
    "select_dtypes()\n",
    "select_dtypes() is a pandas function used to filter columns in a DataFrame based on their data types. \n",
    "It allows you to select numeric, object (string), boolean, datetime, or categorical columns.\n",
    "\n",
    "DataFrame.select_dtypes(include=None, exclude=None)\n",
    "include: A list of data types or strings representing data types to include in the selection. If specified, only columns with these data types will be included.\n",
    "exclude: A list of data types or strings representing data types to exclude from the selection. If specified, columns with these data types will be excluded.\n",
    "\n",
    " Aggregation such as max()\n",
    "titanic_df.select_dtypes(include='number').max() #get the max for each numerical column in the df\n",
    "titanic_df.Fare.max() #get the max for one numerical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e8624-3bf9-42c1-beff-0610ee36193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pandas is a library designed for working with tabulated and tagged data, making it ideal for handling spreadsheets, SQL tables, and more, built on top of NumPy.\n",
    "DataFrames and Series are the two main data structures in Pandas.\n",
    "Series is a one-dimensional array of data with associated labels called the index, while DataFrame is a two-dimensional tabular data structure with labeled rows and columns.\n",
    "Data access in Series and DataFrame can be achieved using integer-based indexing (iloc), label-based indexing (loc), or dictionary-like notation for column access.\n",
    "Series and DataFrame have various methods, such as sort_values(), sort_index(), value_counts(), describe(), info(), nunique(), unique(), dtypes, and select_dtypes()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b7c37-7a04-4e39-9f03-67a24b57e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleaning Data\n",
    "\n",
    "Null values\n",
    "In Python, None is a special constant that represents the absence of a value. It is commonly used to indicate that a variable or function has no value or hasn't been assigned any value. For example, if a function does not explicitly return a value, it implicitly returns None.\n",
    "On the other hand, NaN stands for \"Not a Number\" and is a special value used to represent missing or undefined numerical data. NaN is part of the floating-point representation and is commonly used in numeric data structures like Pandas DataFrames and Series to indicate missing or invalid numerical values.\n",
    "\n",
    "Cleaning Null Values\n",
    "Checking for Null Values:\n",
    "\n",
    "Use isnull() method to check for null values in a DataFrame or Series.\n",
    "Use notnull() method to check for non-null values in a DataFrame or Series.\n",
    "Dropping Null Values:\n",
    "\n",
    "Use dropna() method to remove rows with null values from a DataFrame.\n",
    "Use dropna(axis=1) to remove columns with null values.\n",
    "Filling Null Values:\n",
    "\n",
    "Use fillna(value) method to replace null values with a specific value.\n",
    "Use fillna(method='ffill') to forward-fill null values with the previous non-null value.\n",
    "Use fillna(method='bfill') to backward-fill null values with the next non-null value.\n",
    "\n",
    "Checking for Null Values\n",
    "# Checking for Null Values\n",
    "df.isnull()  # Returns a DataFrame with True where values are null\n",
    "# isnull is an alias of isna\n",
    "\n",
    "When working with large datasets, using isna() or isnull() along with any() and sum() in Pandas becomes essential for quick and efficient data quality assessment.\n",
    "\n",
    "# Check for null values in each column\n",
    "df.isna().any()\n",
    "\n",
    "# Count the number of null values in each column\n",
    "df.isna().sum()\n",
    "\n",
    "df.isna().sum(axis=1)\n",
    "\n",
    "Dropping Null Values\n",
    "# Dropping rows with Null Values\n",
    "df.dropna()  # Removes rows with null values\n",
    "\n",
    "# Dropping columns with  Null Values\n",
    "df.dropna(axis=1)\n",
    "\n",
    "In the dropna() method of Pandas DataFrame, the subset, how, and thresh parameters are used to control the behavior of dropping rows or columns containing NaN (null) values, when we don't want to drop them just because they have one null value:\n",
    "\n",
    "subset: It allows you to specify a subset of columns on which to apply the dropna() operation. Only the rows containing NaN values in the specified subset of columns will be dropped.\n",
    "\n",
    "df.dropna(subset=['Cabin']).tail()\n",
    "how: It specifies the condition for dropping rows. It can take the values 'any', which means to drop rows containing any NaN values in the subset, or 'all', which means to drop rows containing all NaN values in the subset.\n",
    "df.dropna(how='all').tail()\n",
    "\n",
    "thresh: It sets a minimum threshold for the number of non-null values that a row must have in the subset in order to be kept. Rows with fewer non-null values than the specified threshold will be dropped.\n",
    "df.dropna(thresh=3).tail()\n",
    "\n",
    "Filling Null Values\n",
    "\n",
    "fillna() is a Pandas method used to replace NaN (null) values in a DataFrame or Series with specified values.\n",
    "\n",
    "You can use inplace=True to modify the DataFrame directly.\n",
    "# Filling Null Values\n",
    "df.fillna(-1).tail()  # Replaces null values with -1\n",
    "\n",
    "df_na = df.fillna(\"na\")\n",
    "df_na.tail()\n",
    "df_na.dtypes # age is not a float anymore, it's an object now\n",
    "\n",
    "To avoid this, we can select manually in which column to apply the fillna()\n",
    "df.Cabin.fillna(\"na\").tail()\n",
    "\n",
    "We can also use the mean(), median() etc. to fill the null values.\n",
    "df.Age.fillna(df.Age.mean()).tail()\n",
    "\n",
    "Two common methods for filling NaN values are ffill, which forward fills using the last valid value, and bfill, which backward fills using the next valid value.\n",
    "# Forward-fill null values in the Age column\n",
    "df['Age'].fillna(method='ffill').tail()\n",
    "\n",
    "# Backward-fill null values in the Age column\n",
    "df['Age'].fillna(method='bfill').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe6ca8b-f208-449a-b7ae-970f7ae46046",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dealing with Duplicates\n",
    "\n",
    "To identify duplicate rows in a DataFrame, we can use the duplicated() method, which returns a boolean Series indicating whether each row is a duplicate or not. We can then use the sum() method to count the total number of duplicates.\n",
    "df.duplicated().sum()\n",
    "df.duplicated().any()\n",
    "\n",
    "To check for duplicates in specific columns, we can use the duplicated() method with the subset parameter, or just access first to the column and then check with duplicated().\n",
    "\n",
    "df.duplicated(subset=['Age']).sum()# Check for duplicates in specific columns\n",
    "\n",
    "Removing Duplicates\n",
    "\n",
    "Removing Duplicates Based on Specific Columns\n",
    "# Remove duplicates based on specific columns\n",
    "df.drop_duplicates(subset=['Sex', 'Age']) #lets look at the number of rows if we do this\n",
    "\n",
    "By default, drop_duplicates() keeps the first occurrence of each duplicated row. If we want to keep the last occurrence instead, we can set the keep parameter to 'last'\n",
    "# Keep the last occurrence of duplicates\n",
    "df.drop_duplicates(keep='last', inplace=True) # we know there are none but this is how we would do it\n",
    "\n",
    "Resetting the Index\n",
    "When removing duplicates, the DataFrame index may have gaps due to removed rows. To reset the index after removing duplicates, we can use the reset_index() method with the drop=True parameter.\n",
    "# Remove duplicates and reset the index\n",
    "df_without_duplicates = df.copy()\n",
    "df_without_duplicates = df.drop_duplicates(subset=['Sex', 'Age'])\n",
    "df_without_duplicates.tail() # look at the gaps in the index\n",
    "\n",
    "df_without_duplicates.reset_index(drop=True, inplace=True)\n",
    "df_without_duplicates.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d18fe-e598-40f1-b44e-f4fe60f7a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cleaning Column Names\n",
    "\n",
    "In order to modify them, we can assign new column names to df.columns by doing df.columns = [list_of_new_column_names] or we can use the rename() method to just modify a few of them.\n",
    "# We need the whole list of new column names\n",
    "# just modified SibSP to sib_sp\n",
    "\n",
    "df.columns = ['passenger_id', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSP',\n",
    "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
    "\n",
    "df.columns\n",
    "\n",
    "# We just need a dictionary with the columns we want to modify\n",
    "# Getting the name back as it was\n",
    "\n",
    "df.rename(columns= {'passenger_id': 'PassengerId'}, inplace=True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f27bd1b-d2d9-440d-ae67-209b5587c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Using apply(), map(), and applymap()\n",
    "\n",
    "apply()\n",
    "\n",
    "Apply a custom function to a Series.\n",
    "Useful for element-wise transformations.\n",
    "Example: df['squared_numbers'] = df['numbers'].apply(lambda x: x ** 2)\n",
    "map()\n",
    "\n",
    "Transform Series elements based on a dictionary.\n",
    "Replaces elements with corresponding dictionary values.\n",
    "Example: df['gender_mapped'] = df['gender'].map({'M': 'Male', 'F': 'Female'})\n",
    "applymap()\n",
    "\n",
    "Apply a custom function to every element in a DataFrame.\n",
    "Useful for element-wise transformations on entire DataFrames.\n",
    "Example: df = df.applymap(lambda x: x.upper())\n",
    "\n",
    "Apply()\n",
    "\n",
    "# Applying a custom function using apply()\n",
    "def get_yob(age):\n",
    "    return 1912-age #titanic sank in 1912, we will assume is when Age was recorded\n",
    "\n",
    "df['yob'] = df['Age'].apply(get_yob)\n",
    "df.head(3)\n",
    "# Apply and applymap are great for using lambda! This is the same as above\n",
    "\n",
    "df['yob'] = df['Age'].apply(lambda age: 1912-age)\n",
    "\n",
    "df['Fare'] = df['Fare'].apply(lambda num: round(num, 2))\n",
    "df['Fare']\n",
    "\n",
    "Map()\n",
    "\n",
    "# Using map() to transform the 'Sex' column\n",
    "gender_mapping = {'male': 0, 'female': 1}\n",
    "df['Gender_mapped'] = df['Sex'].map(gender_mapping)\n",
    "df.head()\n",
    "\n",
    "# Lets do the same with apply and lambda\n",
    "df.Sex.apply(lambda x: 0 if x==\"male\" else 1)\n",
    "\n",
    "applyMap()\n",
    "\n",
    "# Using applymap() to convert all string columns to uppercase\n",
    "df = df.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "\n",
    "# Displaying the modified DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108e433-4cc4-4d55-82ba-74d1d352b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Filtering Data\n",
    "\n",
    "df.Fare.mean()\n",
    "condition = df.Fare > df.Fare.mean()\n",
    "condition\n",
    "\n",
    "Filtering df\n",
    "filtered_df = df[condition]\n",
    "filtered_df\n",
    "# or what is the same, inside the brackets I give True/False Series in order to filter\n",
    "df[df.Fare > df.Fare.mean()]\n",
    "\n",
    "Using multiple conditions\n",
    "# We can combine boolean operators with filters to add conditions\n",
    "# boolean operators: and is &, or is |\n",
    "df[(df.Fare > df.Fare.mean()) & (df.Fare <= 50)]\n",
    "\n",
    "# To avoid using many filters we can also use .isin()\n",
    "\n",
    "df[(df['Fare'] > 100) & (df['Pclass'].isin([2,3]))]\n",
    "\n",
    "# We can also use between()\n",
    "\n",
    "df[df['Fare'].between(90,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c75e4-5988-4b9e-84d5-88a2666f41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "More Data Manipulation\n",
    "\n",
    "To set an index in pandas, you can use the set_index() method of the DataFrame. This method allows you to specify which column you want to use as the index for the DataFrame.\n",
    "df.set_index('PassengerId',inplace=True)\n",
    "df.head()\n",
    "\n",
    "Adding rows:\n",
    "\n",
    "Use the append() method to add rows to the DataFrame.\n",
    "Removing rows:\n",
    "\n",
    "Use the drop() method with the row index or label to remove specific rows.\n",
    "Adding columns:\n",
    "\n",
    "Using df[new_column], you simply assign a list, Series, or scalar value to the new column name\n",
    "Assign a new column to the DataFrame using bracket notation or the assign() method.\n",
    "Removing columns:\n",
    "\n",
    "Use the drop() method with the column name and axis=1 to remove specific columns.\n",
    "Alternatively, you can use the del keyword to remove a column in-place.\n",
    "\n",
    "df.drop(1) # This deletes the row with index 1\n",
    "\n",
    "# This deletes a column\n",
    "\n",
    "df.drop('Name',axis=1,inplace=True)\n",
    "df.head()\n",
    "\n",
    "# This creates a new column\n",
    "\n",
    "df[\"Survived_bool\"] = df['Survived'].map({0: False, 1: True})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394061a-3865-4405-84f3-d41878477428",
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary\n",
    "\n",
    "Null Values:\n",
    "\n",
    "Null values (also known as missing values) can hinder data analysis and modeling.\n",
    "Use isnull() or isna() to check for null values in a DataFrame or Series.\n",
    "Use any() and sum() to efficiently assess data quality.\n",
    "Use dropna() to remove rows or columns with null values from a DataFrame.\n",
    "Parameters like subset, how, and thresh can control the behavior of dropping rows or columns.\n",
    "Use fillna() to replace null values with specific values, such as mean(), median(), or forward/backward fill.\n",
    "Formatting Data:\n",
    "\n",
    "Use round() and format() to format numeric values.\n",
    "Use f-strings, format() or % to format strings and use string methods like lower(), upper(), title(), strip(), split(), and replace().\n",
    "Cleaning Column Names:\n",
    "\n",
    "Use df.columns to access column names.\n",
    "Modify column names using df.columns or rename().\n",
    "Using apply(), map(), and applymap():\n",
    "\n",
    "apply(): Applies a custom function to a Series.\n",
    "map(): Transforms Series elements based on a dictionary.\n",
    "applymap(): Applies a custom function to every element in a DataFrame.\n",
    "Filtering Data:\n",
    "\n",
    "Filter rows in a DataFrame using boolean indexing.\n",
    "Use comparison operators (<, >, ==) to create conditions.\n",
    "Combine multiple conditions using logical operators (& for 'and', | for 'or').\n",
    "Setting the Index:\n",
    "\n",
    "Use set_index() to set an index for the DataFrame.\n",
    "Adding/Removing Rows and Columns:\n",
    "\n",
    "Use append() to add rows to the DataFrame.\n",
    "Use drop() with the row index/label to remove specific rows.\n",
    "Use bracket notation, assign(), or drop() with axis=1 to add/remove columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd17f9e5-c149-46b8-80fe-be3cecceba92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
